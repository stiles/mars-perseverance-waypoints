{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fdd4e16-e062-4146-9c40-05a340ecc972",
   "metadata": {},
   "source": [
    "# Mars Perseverance Waypoints\n",
    "> This notebook reads and processes more than 1,000 of daily json files listing the locations traveled by the rover, known as Percy, since March 2021. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd6a4cf-3892-4cc9-97de-84f87dc86d7d",
   "metadata": {},
   "source": [
    "#### Load Python tools and Jupyter config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3b1c77c-b670-495b-aca3-e14b06448d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import jupyter_black\n",
    "import altair as alt\n",
    "from glob import glob\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import altair_stiles as altstiles\n",
    "from shapely.geometry import Point, LineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daa1430b-ced1-4480-95b0-2aabaf9b0ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ThemeRegistry.enable('stiles')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jupyter_black.load()\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_colwidth = None\n",
    "alt.themes.register(\"stiles\", altstiles.theme)\n",
    "alt.themes.enable(\"stiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38e657d1-fe82-4a06-b0f2-b9b881adef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = pd.Timestamp(\"today\").strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ec1603-0bda-4d46-a251-1c50f137d197",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbfd20b-7936-4f21-a091-697fca808ab1",
   "metadata": {},
   "source": [
    "## Read and combine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c799af-d3be-4577-96fa-ba056f433607",
   "metadata": {},
   "source": [
    "#### List all JSON files showing daily activity in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ecd2bb8-17f3-4096-88ad-fbf419902945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/raw/waypoints_current_2021-08-07.json',\n",
       " 'data/raw/waypoints_current_2023-03-10.json',\n",
       " 'data/raw/waypoints_current_2021-04-24.json',\n",
       " 'data/raw/waypoints_current_2021-06-19.json',\n",
       " 'data/raw/waypoints_current_2022-07-17.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob(\"data/raw/waypoints_current_*.json\")\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83792e0-c8ef-47d4-a799-685546dd3f59",
   "metadata": {},
   "source": [
    "#### Read each file, normalize the json structure, assign a date column from file name and append in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec83e10b-aaeb-4ba8-a549-3a15205e3487",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for file in files:\n",
    "    base = os.path.basename(file)\n",
    "    date_str = base.replace(\"waypoints_current_\", \"\").replace(\".json\", \"\")\n",
    "\n",
    "    try:\n",
    "        with open(file) as f:\n",
    "            data = json.load(f)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Skipping file {file} due to JSON decoding error.\")\n",
    "        continue\n",
    "\n",
    "    # Extract 'features'\n",
    "    features = data[\"features\"]\n",
    "\n",
    "    # Create a list to collect properties from all features\n",
    "    all_features_properties = []\n",
    "\n",
    "    # Loop through each feature to normalize its properties\n",
    "    for feature in features:\n",
    "        properties = feature[\"properties\"]\n",
    "        properties[\"date\"] = date_str  # Add the date to each property\n",
    "        all_features_properties.append(properties)\n",
    "\n",
    "    # Convert the list of properties dictionaries into a dataframe\n",
    "    properties_df = pd.DataFrame(all_features_properties)\n",
    "\n",
    "    # Append that dataframe to our list\n",
    "    dfs.append(properties_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a98050-2255-4a41-97bb-c416e01c4f45",
   "metadata": {},
   "source": [
    "#### Concatenate all the daily dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "555c8852-b499-404a-b846-5c9593dbf0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8374be-dcd4-4147-be31-23e480a61332",
   "metadata": {},
   "source": [
    "#### Convert longitude and latitude to geometric points and create geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e7f4300-fdec-4aa9-af7a-f6e98c72ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = [Point(xy) for xy in zip(all_data_df[\"lon\"], all_data_df[\"lat\"])]\n",
    "geo_df = gpd.GeoDataFrame(all_data_df, geometry=geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f05fab-e68e-4b0f-b174-d3000f061a42",
   "metadata": {},
   "source": [
    "#### Ensure correct data types for potential date manipulation later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a41ad6cc-04b9-47ef-9d1b-648fc8a42f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df[\"date\"] = pd.to_datetime(geo_df[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabfeb2e-5f77-402b-9be6-26b9d94b7677",
   "metadata": {},
   "source": [
    "#### Make numeric columns numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0368b638-f855-4f54-a6ad-7f8e4163c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = [\n",
    "    \"sol\",\n",
    "    \"elev_geoid\",\n",
    "    # \"easting\",\n",
    "    # \"northing\",\n",
    "    # \"radius\",\n",
    "    # \"roll\",\n",
    "    # \"pitch\",\n",
    "    # \"yaw\",\n",
    "    # \"tilt\",\n",
    "    \"dist_m\",\n",
    "    \"dist_km\",\n",
    "    \"dist_mi\",\n",
    "]\n",
    "\n",
    "for col in columns_to_convert:\n",
    "    geo_df[col] = pd.to_numeric(geo_df[col], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33deb8f7-8088-4239-b5ca-6bcfc3e7f57b",
   "metadata": {},
   "source": [
    "#### Sort geodataframe by earliest date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98954e35-05ca-4d35-8934-f617a031484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = geo_df.sort_values(\"sol\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056f1ce5-5d67-4cfd-aa2b-642ec9072713",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb966959-ce4a-40b8-a252-9cbb3706b636",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee0ca9b-4ff3-43d2-ab0c-dfa7dfbad5bc",
   "metadata": {},
   "source": [
    "#### Filter rows where 'images' is not NaN and contains data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2de8037-fb40-467f-ab15-14a82831cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_images = geo_df[\"images\"].apply(lambda x: isinstance(x, list) and len(x) > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e209e433-bb4a-402e-807e-dbca4f035931",
   "metadata": {},
   "source": [
    "#### Empty dataframe to hold the normalized images data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73a0f367-a3af-48e2-b889-d133b9152b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5346609-cf7f-4860-beb4-8f864201e359",
   "metadata": {},
   "source": [
    "#### Normalize and extract 'images' data where applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bb47465-4755-46b7-a9d1-509900a38eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_images.any():\n",
    "    # Normalize the 'images' data for rows that have it and reset index for merging\n",
    "    images_info = pd.json_normalize(\n",
    "        geo_df[has_images][\"images\"].explode()\n",
    "    ).reset_index()\n",
    "    # Select and rename columns if necessary from images_info\n",
    "    selected_columns = images_info.drop_duplicates(\"index\").set_index(\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee53f5fb-0198-4180-aa45-34f75e39364f",
   "metadata": {},
   "source": [
    "#### Merge the extracted 'images' data back into the original geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6959287-dd95-4acc-af09-cf78b1bc4cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a left join to keep all original rows, adding the new columns where available\n",
    "geo_df = geo_df.merge(\n",
    "    selected_columns, left_index=True, right_index=True, suffixes=(None, \"_drop\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ef3cfc-551f-408f-a054-ee2b461d87d7",
   "metadata": {},
   "source": [
    "#### Clean up the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17be4f0b-9e89-4da6-a4c5-271485b6ab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = geo_df[[col for col in geo_df.columns if not col.endswith(\"_drop\")]]\n",
    "geo_df = geo_df[[col for col in geo_df.columns if not col.endswith(\"_y\")]]\n",
    "geo_df = geo_df[[col for col in geo_df.columns if not col.endswith(\"_x\")]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d5cd6-bf64-4e43-8dd5-e037e9444938",
   "metadata": {},
   "source": [
    "#### Drop columns with all null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddc4dc98-d149-4b00-875c-4f8f4cc9fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df_slim = geo_df.dropna(axis=1, how=\"any\")\n",
    "geo_df_cleaned = geo_df_slim.dropna(subset=[\"geometry\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0de2700-2ff9-4820-8613-1d8a440f2b90",
   "metadata": {},
   "source": [
    "#### Convert the \"[sol](https://en.wikipedia.org/wiki/Mars_sol)\" column to earth days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6716cc16-8479-48b9-87ea-f11d5acce9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_length_in_earth_days = 1 + 39 / (60 * 24) + 35 / (60 * 60 * 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eaa4b390-4ab1-4161-b237-3e7102cfe048",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df_cleaned[\"earth_days\"] = (\n",
    "    geo_df_cleaned[\"sol\"] * sol_length_in_earth_days\n",
    ").round()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffd6f0d-5999-403d-b7e3-f6aa924fac11",
   "metadata": {},
   "source": [
    "#### The result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3a78d77-5849-4fde-a0c6-556973a15f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(geo_df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e744eb-3504-4386-94fe-65e20f9fecfe",
   "metadata": {},
   "source": [
    "#### Set coordinate reference system for Martian geospatial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96198c95-b0f2-4f34-8028-8c0b207ef2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df_cleaned = geo_df_cleaned.set_crs(\"ESRI:104971\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1057dd07-06f4-436b-9cb6-e1e91796ea76",
   "metadata": {},
   "source": [
    "#### Convert points to linestring to get rover path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba7fef23-110f-4462-93c7-312feb0290ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid geometries count: 480\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with None, NaN, or empty geometries\n",
    "valid_geo_df = geo_df_cleaned[\n",
    "    ~(\n",
    "        geo_df_cleaned.geometry.isnull()\n",
    "        | geo_df_cleaned.geometry.apply(lambda geom: geom.is_empty)\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"Valid geometries count: {len(valid_geo_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec88ab2-e120-415a-bcca-cb739843e31d",
   "metadata": {},
   "source": [
    "#### Create the LineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b44ff444-718f-45e4-9ed9-7fceae3dde0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not valid_geo_df.empty:\n",
    "    # Extract coordinate tuples from each Point geometry\n",
    "    coords = [(point.x, point.y) for point in valid_geo_df.geometry]\n",
    "\n",
    "    # Ensure there are at least two points to form a LineString\n",
    "    if len(coords) >= 2:\n",
    "        # Create the LineString from the list of coordinate tuples\n",
    "        linestring = LineString(coords)\n",
    "        # Create a new GeoDataFrame with this LineString\n",
    "        linestrings_gdf = gpd.GeoDataFrame(geometry=[linestring], crs=valid_geo_df.crs)\n",
    "    else:\n",
    "        print(\"Not enough points to form a LineString.\")\n",
    "else:\n",
    "    print(\"No valid geometries to form a LineString.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fd8014-57de-4878-9045-e0e74788b008",
   "metadata": {},
   "source": [
    "#### The result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62bea575-329b-4f27-af7b-58092b8e120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "linestrings_gdf = linestrings_gdf.set_crs(\"ESRI:104971\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a175fb3-f5cf-4688-b6c9-865503cf9e78",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41af18db-4aeb-4259-a7c1-b52471eb8693",
   "metadata": {},
   "source": [
    "## Exports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3831fb4-1062-4cab-9730-933ff07e01f0",
   "metadata": {},
   "source": [
    "#### Rover path as linestring GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eb3f29-4712-4a74-92b5-cf39bbdb2ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "linestrings_gdf.to_file(\n",
    "    f\"data/processed/rover_path_full.geojson\",\n",
    "    driver=\"GeoJSON\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cb79d5-30a1-4d24-b039-c21831387798",
   "metadata": {},
   "source": [
    "#### Rover points as GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8db42507-9079-40be-bdcb-a729bdfeb382",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    geo_df_cleaned[\"date\"] = pd.to_datetime(geo_df_cleaned[\"date\"])\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "466b6df7-ff4a-48bd-9c1c-557f462c54f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df_cleaned.to_file(\n",
    "    f\"data/processed/rover_points_full.geojson\",\n",
    "    driver=\"GeoJSON\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
